{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guitarpro.models import GPException\n",
    "import os, glob, json\n",
    "import guitarpro, librosa, scipy\n",
    "from guitarpro import NoteType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guitar_tracks(song):\n",
    "    \"\"\"\n",
    "    24 Acoustic Guitar (nylon)\n",
    "    25 Acoustic Guitar (steel)\n",
    "    26 Electric Guitar (jazz)\n",
    "    27 Electric Guitar (clean)\n",
    "    28 Electric Guitar (muted)\n",
    "    29 Overdriven Guitar\n",
    "    30 Distortion Guitar\n",
    "    \"\"\"\n",
    "    GUITAR_MIDI_PROGRAMS = [24, 25, 26, 27, 28, 29, 30]\n",
    "    # get all non-percussive tracks (this is still necessary because some drum tracks use a guitar program number)\n",
    "    m_tracks = [track for track in song.tracks if not track.isPercussionTrack]\n",
    "    guitar_tracks = [\n",
    "        track\n",
    "        for track in m_tracks\n",
    "        if track.channel.instrument in GUITAR_MIDI_PROGRAMS and len(track.strings) == 6\n",
    "    ]\n",
    "    return guitar_tracks\n",
    "\n",
    "def get_note_info(note, bpm, margin=None):\n",
    "    \"\"\"\n",
    "    This is the comprehensive function for generating note-level annotation\n",
    "    \n",
    "    `margin` is for passing in the global onset of the segment and calculate the note start time in the segment\n",
    "    \"\"\"\n",
    "    def get_effect_info(effect):\n",
    "        effect_info = {\n",
    "            \"bend\": bool(effect.isBend),  # bool,\n",
    "            \"vibrato\": effect.vibrato,  # bool\n",
    "            \"hammer\": effect.hammer,  # bool\n",
    "            \"slide\": bool(effect.slides),  # bool\n",
    "        }\n",
    "        effect_info[\"bend_type\"] = effect.bend.type.name if effect.isBend else None\n",
    "        effect_info[\"slide_types\"] = (\n",
    "            [slide.name for slide in effect.slides] if effect.slides else None\n",
    "        )\n",
    "        return effect_info\n",
    "\n",
    "    def get_note_time(note, bpm, margin=None):\n",
    "        start = note.beat.start\n",
    "        start_sec = round(((start - 960) / 960) / (bpm / 60), 4)\n",
    "        # the note timing info encoded in a GP file is global, i.e., the start time in the song\n",
    "        # I want the start time in the segment, `margin` is the start time of the segment\n",
    "        if margin:\n",
    "            start_sec = start_sec - margin\n",
    "        dur = note.beat.duration.time\n",
    "        dur_sec = round((dur / 960) / (bpm / 60), 4)\n",
    "        time = {\"start\": start_sec, \"dur\": dur_sec}\n",
    "        return time\n",
    "\n",
    "    note_info = {\n",
    "        \"time\": get_note_time(note, bpm, margin=margin),\n",
    "        \"string\": note.string,\n",
    "        \"fret\": note.value,  # fret number\n",
    "        # \"dur_percent\": note.durationPercent,\n",
    "        \"pitch\": note.realValue,  # self.value + string.value = MIDI note number\n",
    "        # \"type\": note.type.name,  # NoteType class, rest=0, normal=1, tie=2, dead=3\n",
    "        \"effects\": get_effect_info(note.effect),\n",
    "    }\n",
    "    return note_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_tracks(\n",
    "    file,\n",
    "    output_dir,\n",
    "    unify_volume=True,\n",
    "    force_clean=True,\n",
    "    disable_repeats=True,\n",
    "    disable_mixTableChange=True,\n",
    "    disable_other_techniques=True,\n",
    "    force_normal=True\n",
    "):\n",
    "    \"\"\"Split one multi-track GuitarPro file into several one-track GuitarPro files\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the file to split\n",
    "        output_dir (str): The directory for the output files\n",
    "        unify_volume (bool, optional): Whether to adjust the volume of every track to the same level. Defaults to True.\n",
    "        force_clean (bool, optional): Whether to force all tracks to use the clean electric guitar tone. Defaults to True.\n",
    "        disable_repeats (bool, optional): Whether to disable all repeats and alternate endings in the GuitarPro file. Defaults to True.\n",
    "        disable_mixTableChange (bool, optional): Whether to disable mixTableChange instances (e.g., tempo change in the middle of the song). Defaults to True.\n",
    "        disable_other_techniques (bool, optional): Whether to disable other playing techniques (e.g., grace notes, slidein, slideout). Defaults to True.\n",
    "        force_normal (bool, optional): Whether to change all note types (rest, dead, tie) to normal. Defaults to True.\n",
    "    \"\"\"\n",
    "    song = guitarpro.parse(file)\n",
    "    tracks = get_guitar_tracks(song)\n",
    "    for track in tracks:\n",
    "        # unify the volume for rendered audio\n",
    "        if unify_volume:\n",
    "            # default volume is 120 for newly created tracks\n",
    "            track.channel.volume = 120\n",
    "        # force the instrument to be clean electric guitar, so that synthesized audio is automatically clean guitar\n",
    "        if force_clean:\n",
    "            track.channel.instrument = 27\n",
    "\n",
    "        # disable repeats in all measures\n",
    "        # this includes repeats and alternative endings\n",
    "        for measure in track.measures:\n",
    "            if disable_repeats:\n",
    "                # isRepeatOpen is boolean, repeatClose takes -1 or 1,\n",
    "                # repeatAlternative can be whatever number, depending on which repeat group it belongs to\n",
    "                # the following is the default setting in normal bars\n",
    "                measure.header.isRepeatOpen = False\n",
    "                measure.header.repeatClose = -1\n",
    "                measure.header.repeatAlternative = 0\n",
    "            # disable mixTableChange in all beats\n",
    "            # this includes tempo changes, which mess up the calculation of note timings\n",
    "            # and other mysterious effect/instrument changes\n",
    "            if disable_mixTableChange:\n",
    "                for voice in measure.voices:\n",
    "                    for beat in voice.beats:\n",
    "                        beat.effect.mixTableChange = None\n",
    "            \n",
    "            if disable_other_techniques:\n",
    "                for voice in measure.voices:\n",
    "                    for beat in voice.beats:\n",
    "                        beat.effect.fadeIn = False\n",
    "                        beat.effect.tremoloBar = None\n",
    "                        for note in beat.notes:\n",
    "                            note.effect.grace = None\n",
    "                            note.effect.harmonic = None\n",
    "                            note.effect.trill = None\n",
    "                            # slideType values: 1 - shiftSlideTo, 2 - legatoSlideTo, others are ignored\n",
    "                            note.effect.slides = [slide for slide in note.effect.slides if slide.value in [1, 2]]\n",
    "                            note.effect.letRing = False\n",
    "\n",
    "            # force_normal will change the NoteType (tie, rest, dead) to normal,\n",
    "            # tied notes are very messy and hard to handle, so I choose to turn this on\n",
    "            if force_normal:\n",
    "                for voice in measure.voices:\n",
    "                    for beat in voice.beats:\n",
    "                        for note in beat.notes:\n",
    "                            note.type = NoteType.normal\n",
    "\n",
    "        single_track_song = song  # this preserves the metadata in orginal song\n",
    "        single_track_song.tracks = [track]\n",
    "        file_name = \"{}_{}.gp5\".format(\n",
    "            file.split(\"/\")[-1].split(\".\")[0], track.name.replace(\"/\", \" \")\n",
    "        )\n",
    "        try:\n",
    "            guitarpro.write(single_track_song, os.path.join(output_dir, file_name))\n",
    "        except GPException:\n",
    "            print(f\"GPException, removing the corrupt file {file_name}\")\n",
    "            os.remove(os.path.join(output_dir, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_TRACK_GTP_DIR = \"/Volumes/MacOnly/UG_raw/all_time_top_by_hits\"\n",
    "SINGLE_TRACK_GTP_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_hits/clean_single_track_gtps\"\n",
    "SINGLE_TRACK_ANNO_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_hits/clean_single_track_annos\"\n",
    "SINGLE_TRACK_AUDIO_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_hits/clean_single_track_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_TRACK_GTP_DIR = \"/Volumes/MacOnly/UG_raw/all_time_top_by_rating\"\n",
    "SINGLE_TRACK_GTP_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_rating/clean_single_track_gtps\"\n",
    "SINGLE_TRACK_ANNO_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_rating/clean_single_track_annos\"\n",
    "SINGLE_TRACK_AUDIO_DIR = \"/Volumes/MacOnly/UG_rewrite/all_time_top_by_rating/clean_single_track_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate single track gtps from multi track gtps\n",
    "i = 0\n",
    "for file in glob.glob(os.path.join(MULTI_TRACK_GTP_DIR, \"*.gp*\")):\n",
    "    print(i)\n",
    "    get_single_tracks(file, output_dir=SINGLE_TRACK_GTP_DIR, unify_volume=True, force_clean=True, disable_repeats=True, disable_mixTableChange=True, disable_other_techniques=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there are no notes in the second voice of each measure\n",
    "for file in glob.glob(os.path.join(SINGLE_TRACK_GTP_DIR, \"*.gp5\")):\n",
    "    song = guitarpro.parse(file)\n",
    "    track = song.tracks[0]\n",
    "    for measure in track.measures:\n",
    "        for beat in measure.voices[1].beats:\n",
    "            if beat.notes:\n",
    "                print(file)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that every bar has at least one beat, even when it's complete silence\n",
    "for file in glob.glob(os.path.join(SINGLE_TRACK_GTP_DIR, \"*.gp5\")):\n",
    "    song = guitarpro.parse(file)\n",
    "    track = song.tracks[0]\n",
    "    for measure in track.measures:\n",
    "        if len(measure.voices[0].beats) == 0:\n",
    "            print(file)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_vs_mono_vs_silence(song):\n",
    "    \"\"\"Return the time stamps for the start and end of each monophonic / polyphonic / silence segments in the song\n",
    "\n",
    "    Args:\n",
    "        song (Song): A pyguitarpro Song object. The song to analyze\n",
    "\n",
    "    Returns:\n",
    "        list, list, list: A list of (start, end) time stamps for all mono segments, poly segments, and silence segments\n",
    "    \"\"\"\n",
    "    bpm = song.tempo\n",
    "    poly_segments = []\n",
    "    mono_segments = []\n",
    "    silence_segments = []\n",
    "\n",
    "    previous_beat_status = -1\n",
    "    beats = []\n",
    "    for measure in song.tracks[0].measures:\n",
    "        voice = measure.voices[0]\n",
    "        beats.extend(voice.beats)\n",
    "    for beat in beats:\n",
    "        onset = beat.start\n",
    "        onset_sec = round(((onset - 960) / 960) / (bpm / 60), 4)\n",
    "        dur = beat.duration.time\n",
    "        dur_sec = round((dur / 960) / (bpm / 60), 4)\n",
    "        offset_sec = onset_sec + dur_sec\n",
    "        # 2 for polyphonic, 1 for monophonic, 0 for silence\n",
    "        if len(beat.notes) == 0:\n",
    "            beat_status = 0\n",
    "        elif len(beat.notes) == 1:\n",
    "            beat_status = 1\n",
    "        else:\n",
    "            beat_status = 2\n",
    "        if beat_status != previous_beat_status:\n",
    "            # if current beat status is different from the previous beat, add the timing to the output list\n",
    "            # the following lines can obviously be better written, I leave it like this just for clarity\n",
    "            if beat_status == 2:\n",
    "                poly_segments.append([onset_sec, offset_sec])\n",
    "            elif beat_status == 1:\n",
    "                mono_segments.append([onset_sec, offset_sec])\n",
    "            else:\n",
    "                assert beat_status == 0\n",
    "                silence_segments.append([onset_sec, offset_sec])\n",
    "        else:\n",
    "            # if current beat status is the same as the previous one, update the offset of the previous entry\n",
    "            if beat_status == 2:\n",
    "                poly_segments[-1][1] = offset_sec\n",
    "            elif beat_status == 1:\n",
    "                mono_segments[-1][1] = offset_sec\n",
    "            else:\n",
    "                assert beat_status == 0\n",
    "                silence_segments[-1][1] = offset_sec\n",
    "        previous_beat_status = beat_status\n",
    "    return poly_segments, mono_segments, silence_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_anno(file, anno_dir):\n",
    "    \"\"\"Generate note-info annotation JSON files, one annotation file per single track GP file\n",
    "\n",
    "    The input file is a clean single-track GuitarPro file (the whole track). \n",
    "    Only mono notes are recorded. \n",
    "    \n",
    "    Args:\n",
    "        file (str): The path to the single-track GuitarPro file\n",
    "        anno_dir (str): The directory to put generated JSON file\n",
    "    \"\"\"\n",
    "    song = guitarpro.parse(file)\n",
    "    bpm = song.tempo\n",
    "    # put all beats of the song in one place\n",
    "    beats = []\n",
    "    for measure in song.tracks[0].measures:\n",
    "        beats.extend(measure.voices[0].beats)\n",
    "\n",
    "    note_infos = []\n",
    "\n",
    "    for beat in beats:\n",
    "        if len(beat.notes) == 1:\n",
    "            note = beat.notes[0]\n",
    "            note_info = get_note_info(note, bpm, margin=None)\n",
    "            note_infos.append(note_info)\n",
    "\n",
    "    track_title, _ = os.path.splitext(file.split(\"/\")[-1])\n",
    "    with open(os.path.join(anno_dir, f\"{track_title}.json\"), \"w\") as outfile:\n",
    "        json.dump(note_infos, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate global annotation from single track gtps\n",
    "i = 0\n",
    "for file in glob.glob(os.path.join(SINGLE_TRACK_GTP_DIR, \"*.gp5\")):\n",
    "    i += 1\n",
    "    gen_anno(file, anno_dir=SINGLE_TRACK_ANNO_DIR)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams for mono detector\n",
    "N_MFCC = [8, 13, 20, 40]\n",
    "FRAME_SIZE = [1024, 2048, 4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate gt for mono detector, using all combinations of n_mfcc and frame_size\n",
    "for n_mfcc in N_MFCC:\n",
    "    for frame_size in FRAME_SIZE:\n",
    "        poly_features_with_label = []\n",
    "        mono_features_with_label = []\n",
    "\n",
    "        i = 0\n",
    "        for audio_file in glob.glob(os.path.join(SINGLE_TRACK_AUDIO_DIR, \"*.wav\")):\n",
    "            track_name, _ = os.path.splitext(audio_file.split(\"/\")[-1])\n",
    "            i += 1\n",
    "            print(track_name, i)\n",
    "            gtp_file = os.path.join(SINGLE_TRACK_GTP_DIR, track_name + \".gp5\")\n",
    "            \n",
    "            y, sr = librosa.load(audio_file, sr=None)\n",
    "            p, m, _ = poly_vs_mono_vs_silence(guitarpro.parse(gtp_file))\n",
    "\n",
    "            for poly_timestamp in p:\n",
    "                start_sp = int(poly_timestamp[0] * sr)\n",
    "                end_sp = int(poly_timestamp[1] * sr)\n",
    "                y_segment = y[start_sp : end_sp]\n",
    "                if len(y_segment) < frame_size:\n",
    "                    continue\n",
    "\n",
    "                mel_spec = librosa.feature.melspectrogram(y_segment, sr, n_fft=frame_size, hop_length=frame_size)\n",
    "                log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "                mfcc = librosa.feature.mfcc(S=log_mel_spec, n_mfcc=n_mfcc)\n",
    "\n",
    "                label = np.ones((1, mfcc.shape[1]))\n",
    "                feature_with_label = np.append(mfcc, label, axis=0)\n",
    "                poly_features_with_label.append(feature_with_label)\n",
    "\n",
    "            for mono_timestamp in m:\n",
    "                start_sp = int(mono_timestamp[0] * sr)\n",
    "                end_sp = int(mono_timestamp[1] * sr)\n",
    "                y_segment = y[start_sp : end_sp]\n",
    "                if len(y_segment) < frame_size:\n",
    "                    continue\n",
    "\n",
    "                mel_spec = librosa.feature.melspectrogram(y_segment, sr, n_fft=frame_size, hop_length=frame_size)\n",
    "                log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "                mfcc = librosa.feature.mfcc(S=log_mel_spec, n_mfcc=n_mfcc)\n",
    "\n",
    "                label = np.zeros((1, mfcc.shape[1]))\n",
    "                feature_with_label = np.append(mfcc, label, axis=0)\n",
    "                mono_features_with_label.append(feature_with_label)\n",
    "\n",
    "        poly_data = np.concatenate(poly_features_with_label, axis=1)\n",
    "        mono_data = np.concatenate(mono_features_with_label, axis=1)\n",
    "\n",
    "        print(poly_data.shape)\n",
    "        print(mono_data.shape)\n",
    "\n",
    "        # combine mono and poly and save to file\n",
    "        data = np.concatenate((mono_data, poly_data), axis=1)\n",
    "        data = data.transpose()\n",
    "        print(data.shape)\n",
    "\n",
    "        np.save(file=f\"/Users/jw/Documents/mono_detector_data/MFCC_{n_mfcc}_FR_{frame_size}.npy\", arr=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction function with resampling\n",
    "def extract_features(note_audio):\n",
    "    \"\"\"The one function that calculates all the features.\n",
    "\n",
    "    The returned 1D feature vector includes:\n",
    "\n",
    "    * F0s, F0 diffs\n",
    "    * MFCCs, MFCC diffs\n",
    "    * Spectral.timbral features and their diffs\n",
    "\n",
    "    Args:\n",
    "        note_audio (array): The audio signal of a note event.\n",
    "\n",
    "    Returns:\n",
    "        array: The final feature vector for the input note event.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_all_stats(a):\n",
    "        \"\"\"Given a 1D time series, compute the 6 statistics.\n",
    "\n",
    "        Args:\n",
    "            a (array): The input time series, of the shape (n,)\n",
    "\n",
    "        Returns:\n",
    "            array: An array containing the statistics, of the shape (6,)\n",
    "        \"\"\"\n",
    "        assert a.ndim == 1\n",
    "        mean = np.mean(a)\n",
    "        std = np.std(a)\n",
    "        max = np.max(a)\n",
    "        min = np.min(a)\n",
    "        skewness = scipy.stats.skew(a, nan_policy=\"raise\")\n",
    "        kurtosis = scipy.stats.kurtosis(a, nan_policy=\"raise\")\n",
    "\n",
    "        stats = np.array([mean, std, max, min, skewness, kurtosis])\n",
    "        assert stats.shape == (6,)\n",
    "        return stats\n",
    "\n",
    "    def extract_mfccs(note_audio):\n",
    "        \"\"\"Given the audio signal of a note event, compute the MFCC features.\n",
    "        \n",
    "        The MFCC features include the mean and std of the MFCCs aggregated over the note event, \n",
    "        and the mean and std of the 1st order differences aggregated over the note event.\n",
    "\n",
    "        Args:\n",
    "            note_audio (array): The note event audio signal\n",
    "\n",
    "        Returns:\n",
    "            array: The MFCC feature vector, of the shape (80,)\n",
    "        \"\"\"\n",
    "        mfccs = librosa.feature.mfcc(note_audio, sr=sr)\n",
    "        mfccs_diff = np.diff(mfccs, n=1)\n",
    "        assert mfccs.shape[1] == mfccs_diff.shape[1] + 1\n",
    "\n",
    "        mfccs_mean = np.mean(mfccs, axis=1)\n",
    "        assert mfccs_mean.shape == (20,)\n",
    "        mfccs_diff_mean = np.mean(mfccs_diff, axis=1)\n",
    "        assert mfccs_diff_mean.shape == (20,)\n",
    "\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "        assert mfccs_std.shape == (20,)\n",
    "        mfccs_diff_std = np.std(mfccs_diff, axis=1)\n",
    "        assert mfccs_diff_std.shape == (20,)\n",
    "\n",
    "        mfcc_feature = np.concatenate((mfccs_mean, mfccs_diff_mean, mfccs_std, mfccs_diff_std), axis=0)\n",
    "        assert mfcc_feature.shape == (80,)\n",
    "        return mfcc_feature\n",
    "\n",
    "    # get pitch features\n",
    "    # this uses fill_na=None to give a guess for unvoiced frames, so there's no NaN in f0\n",
    "    f0, _, _ = librosa.pyin(note_audio, fmin=librosa.note_to_hz(\"C2\"), fmax=librosa.note_to_hz(\"G6\"), sr=sr, fill_na=None)\n",
    "    # this eliminates the NaNs in the estimated F0\n",
    "    # pitch = f0[voiced]\n",
    "    pitch = f0\n",
    "    pitch_diff = np.diff(pitch, n=1)\n",
    "\n",
    "    assert pitch.ndim == 1\n",
    "    assert pitch_diff.ndim == 1\n",
    "    assert pitch.shape[0] == pitch_diff.shape[0] + 1\n",
    "\n",
    "    # get spectral/timbral features\n",
    "    centroid = np.squeeze(librosa.feature.spectral_centroid(note_audio, sr))\n",
    "    bandwidth = np.squeeze(librosa.feature.spectral_bandwidth(note_audio, sr))\n",
    "    flatness = np.squeeze(librosa.feature.spectral_flatness(note_audio))\n",
    "    rolloff = np.squeeze(librosa.feature.spectral_rolloff(note_audio, sr))\n",
    "    zero_crossing = np.squeeze(librosa.feature.zero_crossing_rate(note_audio))\n",
    "    flux = librosa.onset.onset_strength(note_audio, sr)\n",
    "    specs = np.array([centroid, bandwidth, flatness, rolloff, zero_crossing, flux])\n",
    "    specs_diff = np.diff(specs, n=1)\n",
    "\n",
    "    assert specs.ndim == 2\n",
    "    assert specs_diff.ndim == 2\n",
    "    assert specs.shape[1] == specs_diff.shape[1] + 1\n",
    "\n",
    "    pitch_stats = get_all_stats(pitch)\n",
    "    pitch_diff_stats = get_all_stats(pitch_diff)\n",
    "\n",
    "    assert pitch_stats.shape == (6,)\n",
    "    assert pitch_diff_stats.shape == (6,)\n",
    "\n",
    "    feature = np.concatenate((pitch_stats, pitch_diff_stats), axis=0)\n",
    "\n",
    "    for spec in specs:\n",
    "        assert spec.ndim == 1\n",
    "        spec_stats = get_all_stats(spec)\n",
    "        assert spec_stats.shape == (6,)\n",
    "        feature = np.concatenate((feature, spec_stats), axis=0)\n",
    "    for spec_diff in specs_diff:\n",
    "        assert spec_diff.ndim == 1\n",
    "        spec_diff_stats = get_all_stats(spec_diff)\n",
    "        assert spec_diff_stats.shape == (6,)\n",
    "        feature = np.concatenate((feature, spec_diff_stats), axis=0)\n",
    "    assert feature.shape == (84,)\n",
    "\n",
    "    mfcc_feature = extract_mfccs(note_audio)\n",
    "    feature = np.concatenate((feature, mfcc_feature), axis=0)\n",
    "    assert feature.shape == (164,)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction function without resampling\n",
    "def extract_features(y, sr, frame_size, hop_size):\n",
    "    mfcc = librosa.feature.mfcc(y, sr=sr, n_fft=frame_size, hop_length=hop_size)\n",
    "    pitch, _, _ = librosa.pyin(y, fmin=librosa.note_to_hz(\"C2\"), fmax=librosa.note_to_hz(\"G6\"), frame_length=frame_size, hop_length=hop_size, sr=sr, fill_na=None)\n",
    "    centroid = np.squeeze(librosa.feature.spectral_centroid(y, sr, n_fft=frame_size, hop_length=hop_size))\n",
    "    bandwidth = np.squeeze(librosa.feature.spectral_bandwidth(y, sr, n_fft=frame_size, hop_length=hop_size))\n",
    "    flatness = np.squeeze(librosa.feature.spectral_flatness(y, n_fft=frame_size, hop_length=hop_size))\n",
    "    rolloff = np.squeeze(librosa.feature.spectral_rolloff(y, sr, n_fft=frame_size, hop_length=hop_size))\n",
    "    zero_crossing = np.squeeze(librosa.feature.zero_crossing_rate(y, frame_length=frame_size, hop_length=hop_size))\n",
    "    flux = librosa.onset.onset_strength(y, sr, n_fft=frame_size, hop_length=hop_size)\n",
    "\n",
    "    non_mfccs = np.array([pitch, centroid, bandwidth, flatness, rolloff, zero_crossing, flux])\n",
    "    features = np.concatenate((mfcc, non_mfccs), axis=0)\n",
    "\n",
    "    features_delta = librosa.feature.delta(features, order=1)\n",
    "    features_accel = librosa.feature.delta(features, order=2)\n",
    "\n",
    "    all_features = np.concatenate((features, features_delta, features_accel), axis=0) # (81, 13127)\n",
    "    assert all_features.shape[0] == 81\n",
    "    return all_features\n",
    "\n",
    "def get_all_stats(a):\n",
    "    \"\"\"Given a 2D matrix, compute and concatenate the 6 statistics.\n",
    "\n",
    "    Args:\n",
    "        a (array): The input time series, of the shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        array: An array containing the statistics, of the shape (6,)\n",
    "    \"\"\"\n",
    "    assert a.ndim == 2\n",
    "    mean = np.mean(a, axis=1)\n",
    "    std = np.std(a, axis=1)\n",
    "    max = np.max(a, axis=1)\n",
    "    min = np.min(a, axis=1)\n",
    "    skewness = scipy.stats.skew(a, axis=1, nan_policy=\"raise\")\n",
    "    kurtosis = scipy.stats.kurtosis(a, axis=1, nan_policy=\"raise\")\n",
    "\n",
    "    stats = np.concatenate((mean, std, max, min, skewness, kurtosis), axis=0)\n",
    "    assert stats.shape[0] == a.shape[0] * 6\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameter combination from note-event separation\n",
    "frame_size = 1024\n",
    "hop_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for note events/transition events \n",
    "notes_data = []\n",
    "trans_data = []\n",
    "j = 0\n",
    "for audio_file in glob.glob(os.path.join(SINGLE_TRACK_AUDIO_DIR, \"*.wav\")):\n",
    "    track_name, _ = os.path.splitext(audio_file.split(\"/\")[-1])\n",
    "    j += 1\n",
    "    print(track_name, j)\n",
    "    anno_file = os.path.join(SINGLE_TRACK_ANNO_DIR, track_name + \".json\")\n",
    "\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    all_features = extract_features(y, sr, frame_size, hop_size)\n",
    "\n",
    "    with open(anno_file) as anno:\n",
    "        annotation = json.load(anno)\n",
    "\n",
    "    for i in range(len(annotation)):\n",
    "        note_event = annotation[i]\n",
    "\n",
    "        onset = note_event[\"time\"][\"start\"]\n",
    "        dur = note_event[\"time\"][\"dur\"]\n",
    "        offset = onset + dur\n",
    "        onset_fr = librosa.time_to_frames(onset, sr=sr, hop_length=hop_size)\n",
    "        offset_fr = librosa.time_to_frames(offset, sr=sr, hop_length=hop_size)\n",
    "\n",
    "        # if note duration is shorter than one frame, discard it\n",
    "        if offset_fr - onset_fr < 1:\n",
    "            continue\n",
    "\n",
    "        note_feature = all_features[:, onset_fr : offset_fr+1]\n",
    "        note_aggregation = get_all_stats(note_feature)\n",
    "\n",
    "        if note_event[\"effects\"][\"vibrato\"]:\n",
    "            label = 2\n",
    "        elif note_event[\"effects\"][\"bend\"]:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        feature_w_label = np.append(note_aggregation, label)\n",
    "        notes_data.append(feature_w_label)\n",
    "\n",
    "        # if the note event is the last one in the song, ignore its transitions \n",
    "        if i == len(annotation) - 1:\n",
    "            break\n",
    "        \n",
    "        next_note_event = annotation[i + 1]\n",
    "        # if the next note event doesn't immediately follow the current note event, ignore the transition\n",
    "        if next_note_event[\"time\"][\"start\"] - offset > 0.05:\n",
    "            continue\n",
    "\n",
    "        tran_onset_fr = offset_fr - 2\n",
    "        tran_offset_fr = offset_fr + 2\n",
    "        tran_feature = all_features[:, tran_onset_fr : tran_offset_fr+1]\n",
    "        tran_aggregation = get_all_stats(tran_feature)\n",
    "        \n",
    "        if note_event[\"effects\"][\"hammer\"]:\n",
    "            if note_event[\"pitch\"] < next_note_event[\"pitch\"]:\n",
    "                # hammer-on\n",
    "                tran_label = 3\n",
    "            elif note_event[\"pitch\"] > next_note_event[\"pitch\"]:\n",
    "                # pull-off\n",
    "                tran_label = 4\n",
    "            else:\n",
    "                tran_label = 0\n",
    "        elif note_event[\"effects\"][\"slide\"]:\n",
    "            tran_label = 5\n",
    "        else:\n",
    "            tran_label = 0\n",
    "        tran_feature_w_label = np.append(tran_aggregation, tran_label)\n",
    "        trans_data.append(tran_feature_w_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_notes_data = np.unique(notes_data, axis=0)\n",
    "u_trans_data = np.unique(trans_data, axis=0)\n",
    "print(u_notes_data.shape)\n",
    "print(u_trans_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/Users/jw/Documents/extensive_features/hits_data_notes.npy\", u_notes_data)\n",
    "u_notes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/Users/jw/Documents/extensive_features/hits_data_trans.npy\", u_trans_data)\n",
    "u_trans_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = u_notes_data[:, -1]\n",
    "normal = label == 0\n",
    "bend = label == 1\n",
    "vibrato = label == 2\n",
    "hammer = label == 3\n",
    "pull = label == 4\n",
    "slide = label == 5\n",
    "print(f\"normal: {np.sum(normal)}, bend: {np.sum(bend)}, vibrato: {np.sum(vibrato)}, hammer: {np.sum(hammer)}, pull: {np.sum(pull)}, slide: {np.sum(slide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = u_trans_data[:, -1]\n",
    "normal = label == 0\n",
    "bend = label == 1\n",
    "vibrato = label == 2\n",
    "hammer = label == 3\n",
    "pull = label == 4\n",
    "slide = label == 5\n",
    "print(f\"normal: {np.sum(normal)}, bend: {np.sum(bend)}, vibrato: {np.sum(vibrato)}, hammer: {np.sum(hammer)}, pull: {np.sum(pull)}, slide: {np.sum(slide)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_data = np.array(notes_data)\n",
    "trans_data = np.array(trans_data)\n",
    "print(notes_data.shape, trans_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_data = np.concatenate((notes_data, trans_data), axis=0)\n",
    "hits_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = np.concatenate((notes_data, trans_data), axis=0)\n",
    "rating_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hits_data = np.unique(hits_data, axis=0)\n",
    "np.save(\"/Users/jw/Documents/extensive_features/hits_data.npy\", u_hits_data)\n",
    "u_hits_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_rating_data = np.unique(rating_data, axis=0)\n",
    "np.save(\"/Users/jw/Documents/final_features/rating_data.npy\", u_rating_data)\n",
    "u_rating_data.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e4299a6bfeee03721df81a04beb561ffa0442fcfce618d29889931a6d6e4527"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
