{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import librosa\n",
    "import os, json, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, mir_eval\n",
    "import numpy as np\n",
    "from f0_analysis_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training PT classifier\n",
    "According to the annotations, split the mono audio segments into note events. \n",
    "\n",
    "Without candidate selection, \n",
    "\n",
    "directly classify the note events into:\n",
    "* normal\n",
    "* bend/release/prebend... (this will be further analyzed using signal processing)\n",
    "* vibrato\n",
    "\n",
    "directly classify the transitions (100 ms around the offset of note events) into:\n",
    "* normal\n",
    "* hammer/pull... (this will be further analyzed using signal processing)\n",
    "* slide\n",
    "\n",
    "Two classifiers, each distinguish between three classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code for generating the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(note_audio):\n",
    "    return np.random.random((10,))\n",
    "def extract_tran_features(tran_audio):\n",
    "    return np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_data = [] # huge matrix with features and labels for note events (normal, bend/release, vibrato)\n",
    "trans_data = [] # huge matrix with features and labels for note events (normal, hm/po, slide)\n",
    "\n",
    "file = \"Guns N' Roses - Welcome To The Jungle (ver 3)_Solo Guitar_0_0s.wav\"\n",
    "y, sr = librosa.load(os.path.join(FILTERED_AUDIO_DIR, file), sr=None)\n",
    "\n",
    "anno_file = find_anno(file)\n",
    "with open(anno_file) as anno:\n",
    "    annotation = json.load(anno)\n",
    "for i in range(len(annotation)):\n",
    "    note_event = annotation[i]\n",
    "    onset = note_event[\"time\"][\"start\"]\n",
    "    offset = onset + note_event[\"time\"][\"dur\"]\n",
    "    onset_sp = librosa.time_to_samples(onset, sr=sr)\n",
    "    offset_sp = librosa.time_to_samples(offset, sr=sr)\n",
    "    note_audio = y[onset_sp : offset_sp]\n",
    "    feature = extract_features(note_audio)\n",
    "    if note_event[\"effects\"][\"bend\"]:\n",
    "        label = 1\n",
    "    elif note_event[\"effects\"][\"vibrato\"]:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 0\n",
    "    feature_w_label = np.append(feature, label)\n",
    "    notes_data.append(feature_w_label)\n",
    "\n",
    "    # if the note event is the last one in the file, ignore its transitions \n",
    "    # because the transition won't be captured in the audio\n",
    "    if i == len(annotation) - 1:\n",
    "        break\n",
    "    tran_onset_sp = offset_sp - librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_offset_sp = offset_sp + librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_audio = y[tran_onset_sp : tran_offset_sp]\n",
    "    tran_feature = extract_tran_features(tran_audio)\n",
    "    if note_event[\"effects\"][\"hammer\"]:\n",
    "        tran_label = 1\n",
    "    elif note_event[\"effects\"][\"slide\"]:\n",
    "        tran_label = 2\n",
    "    else:\n",
    "        tran_label = 0\n",
    "    tran_feature_w_label = np.append(tran_feature, tran_label)\n",
    "    trans_data.append(tran_feature_w_label)\n",
    "\n",
    "notes_data = np.array(notes_data)\n",
    "trans_data = np.array(trans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing audio features\n",
    "Frame-level features aggregated for the duration of the note event. \n",
    "\n",
    "Statistics: mean, std, max, min, skewness, kurtosis\n",
    "\n",
    "All stats of spectral centroid, brightness, spread, skewness, kurtosis, flux, roll-off entropy, irregularity, roughness, inharmonicity, zero-crossing, low-energy ratio and their 1st order difference = 156\n",
    "\n",
    "All stats of pitch and 1st order difference = 12\n",
    "\n",
    "Mean and std of 40-MFCC and 1st order difference = 160\n",
    "\n",
    "Run this part on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(note_audio):\n",
    "    return np.random.random((10,))\n",
    "def extract_tran_features(tran_audio):\n",
    "    return np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59d85d0919029fe908500b29ceb55c54859f0fca8114ead43d175dc230632326"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('GTP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
