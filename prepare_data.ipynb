{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import librosa\n",
    "import os, json, glob\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, mir_eval\n",
    "import numpy as np\n",
    "import scipy\n",
    "from f0_analysis_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training PT classifier\n",
    "According to the annotations, split the mono audio segments into note events. \n",
    "\n",
    "Without candidate selection, \n",
    "\n",
    "directly classify the note events into:\n",
    "* normal\n",
    "* bend/release/prebend... (this will be further analyzed using signal processing)\n",
    "* vibrato\n",
    "\n",
    "directly classify the transitions (100 ms around the offset of note events) into:\n",
    "* normal\n",
    "* hammer/pull... (this will be further analyzed using signal processing)\n",
    "* slide\n",
    "\n",
    "Two classifiers, each distinguish between three classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code for generating the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(note_audio):\n",
    "    return np.random.random((10,))\n",
    "def extract_tran_features(tran_audio):\n",
    "    return np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_data = [] # huge matrix with features and labels for note events (normal, bend/release, vibrato)\n",
    "trans_data = [] # huge matrix with features and labels for note events (normal, hm/po, slide)\n",
    "\n",
    "file = \"Guns N' Roses - Welcome To The Jungle (ver 3)_Solo Guitar_0_0s.wav\"\n",
    "y, sr = librosa.load(os.path.join(FILTERED_AUDIO_DIR, file), sr=None)\n",
    "\n",
    "anno_file = find_anno(file)\n",
    "with open(anno_file) as anno:\n",
    "    annotation = json.load(anno)\n",
    "for i in range(len(annotation)):\n",
    "    note_event = annotation[i]\n",
    "    onset = note_event[\"time\"][\"start\"]\n",
    "    offset = onset + note_event[\"time\"][\"dur\"]\n",
    "    onset_sp = librosa.time_to_samples(onset, sr=sr)\n",
    "    offset_sp = librosa.time_to_samples(offset, sr=sr)\n",
    "    note_audio = y[onset_sp : offset_sp]\n",
    "    feature = extract_features(note_audio)\n",
    "    if note_event[\"effects\"][\"bend\"]:\n",
    "        label = 1\n",
    "    elif note_event[\"effects\"][\"vibrato\"]:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 0\n",
    "    feature_w_label = np.append(feature, label)\n",
    "    notes_data.append(feature_w_label)\n",
    "\n",
    "    # if the note event is the last one in the file, ignore its transitions \n",
    "    # because the transition won't be captured in the audio\n",
    "    if i == len(annotation) - 1:\n",
    "        break\n",
    "    tran_onset_sp = offset_sp - librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_offset_sp = offset_sp + librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_audio = y[tran_onset_sp : tran_offset_sp]\n",
    "    tran_feature = extract_tran_features(tran_audio)\n",
    "    if note_event[\"effects\"][\"hammer\"]:\n",
    "        tran_label = 1\n",
    "    elif note_event[\"effects\"][\"slide\"]:\n",
    "        tran_label = 2\n",
    "    else:\n",
    "        tran_label = 0\n",
    "    tran_feature_w_label = np.append(tran_feature, tran_label)\n",
    "    trans_data.append(tran_feature_w_label)\n",
    "\n",
    "notes_data = np.array(notes_data)\n",
    "trans_data = np.array(trans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing audio features\n",
    "Frame-level features aggregated for the duration of the note event. \n",
    "\n",
    "Statistics: mean, std, max, min, skewness, kurtosis\n",
    "\n",
    "All stats of spectral centroid, brightness?, spread, skewness, kurtosis, flux, roll-off, entropy, irregularity, roughness, inharmonicity, zero-crossing, low-energy ratio and their 1st order difference = 156\n",
    "\n",
    "All stats of pitch and 1st order difference = 12\n",
    "\n",
    "Mean and std of 40-MFCC and 1st order difference = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary audio/anno path \n",
    "AUDIO_DIR = \"samples/audio\"\n",
    "ANNO_DIR = \"samples/anno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stats(a):\n",
    "    \"\"\"Given a 1D time series, compute the 6 statistics.\n",
    "\n",
    "    Args:\n",
    "        a (array): The input time series, of the shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        array: An array containing the statistics, of the shape (6,)\n",
    "    \"\"\"\n",
    "    assert a.ndim == 1\n",
    "    mean = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    max = np.max(a)\n",
    "    min = np.min(a)\n",
    "    skewness = scipy.stats.skew(a, nan_policy=\"raise\")\n",
    "    kurtosis = scipy.stats.kurtosis(a, nan_policy=\"raise\")\n",
    "\n",
    "    stats = np.array([mean, std, max, min, skewness, kurtosis])\n",
    "    assert stats.shape == (6,)\n",
    "    return stats\n",
    "\n",
    "\n",
    "def extract_mfccs(note_audio):\n",
    "    \"\"\"Given the audio signal of a note event, compute the MFCC features.\n",
    "    \n",
    "    The MFCC features include the mean and std of the MFCCs aggregated over the note event, \n",
    "    and the mean and std of the 1st order differences aggregated over the note event.\n",
    "\n",
    "    Args:\n",
    "        note_audio (array): The note event audio signal\n",
    "\n",
    "    Returns:\n",
    "        array: The MFCC feature vector, of the shape (80,)\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(note_audio, sr=sr)\n",
    "    mfccs_diff = np.diff(mfccs, n=1)\n",
    "    assert mfccs.shape[1] == mfccs_diff.shape[1] + 1\n",
    "\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    assert mfccs_mean.shape == (20,)\n",
    "    mfccs_diff_mean = np.mean(mfccs_diff, axis=1)\n",
    "    assert mfccs_diff_mean.shape == (20,)\n",
    "\n",
    "    mfccs_std = np.std(mfccs, axis=1)\n",
    "    assert mfccs_std.shape == (20,)\n",
    "    mfccs_diff_std = np.std(mfccs_diff, axis=1)\n",
    "    assert mfccs_diff_std.shape == (20,)\n",
    "\n",
    "    mfcc_feature = np.concatenate((mfccs_mean, mfccs_diff_mean, mfccs_std, mfccs_diff_std), axis=0)\n",
    "    assert mfcc_feature.shape == (80,)\n",
    "    return mfcc_feature\n",
    "\n",
    "\n",
    "def extract_features(note_audio):\n",
    "    \"\"\"The one function that calculates all the features.\n",
    "\n",
    "    The returned 1D feature vector includes:\n",
    "\n",
    "    * F0s, F0 diffs\n",
    "    * MFCCs, MFCC diffs\n",
    "    * Spectral.timbral features and their diffs\n",
    "\n",
    "    Args:\n",
    "        note_audio (array): The audio signal of a note event.\n",
    "\n",
    "    Returns:\n",
    "        array: The final feature vector for the input note event.\n",
    "    \"\"\"\n",
    "    # get pitch features\n",
    "    # this uses fill_na=None to give a guess for unvoiced frames, so there's no NaN in f0\n",
    "    f0, voiced, _ = librosa.pyin(note_audio, fmin=librosa.note_to_hz(\"C2\"), fmax=librosa.note_to_hz(\"G6\"), sr=sr, fill_na=None)\n",
    "    # this eliminates the NaNs in the estimated F0\n",
    "    # pitch = f0[voiced]\n",
    "    pitch = f0\n",
    "    pitch_diff = np.diff(pitch, n=1)\n",
    "\n",
    "    assert pitch.ndim == 1\n",
    "    assert pitch_diff.ndim == 1\n",
    "    assert pitch.shape[0] == pitch_diff.shape[0] + 1\n",
    "\n",
    "    # get spectral/timbral features\n",
    "    centroid = np.squeeze(librosa.feature.spectral_centroid(note_audio, sr))\n",
    "    bandwidth = np.squeeze(librosa.feature.spectral_bandwidth(note_audio, sr))\n",
    "    flatness = np.squeeze(librosa.feature.spectral_flatness(note_audio))\n",
    "    rolloff = np.squeeze(librosa.feature.spectral_rolloff(note_audio, sr))\n",
    "    zero_crossing = np.squeeze(librosa.feature.zero_crossing_rate(note_audio))\n",
    "    flux = librosa.onset.onset_strength(note_audio, sr)\n",
    "    specs = np.array([centroid, bandwidth, flatness, rolloff, zero_crossing, flux])\n",
    "    specs_diff = np.diff(specs, n=1)\n",
    "\n",
    "    assert specs.ndim == 2\n",
    "    assert specs_diff.ndim == 2\n",
    "    assert specs.shape[1] == specs_diff.shape[1] + 1\n",
    "\n",
    "    pitch_stats = get_all_stats(pitch)\n",
    "    pitch_diff_stats = get_all_stats(pitch_diff)\n",
    "\n",
    "    assert pitch_stats.shape == (6,)\n",
    "    assert pitch_diff_stats.shape == (6,)\n",
    "\n",
    "    feature = np.concatenate((pitch_stats, pitch_diff_stats), axis=0)\n",
    "\n",
    "    for spec in specs:\n",
    "        assert spec.ndim == 1\n",
    "        spec_stats = get_all_stats(spec)\n",
    "        assert spec_stats.shape == (6,)\n",
    "        feature = np.concatenate((feature, spec_stats), axis=0)\n",
    "    for spec_diff in specs_diff:\n",
    "        assert spec_diff.ndim == 1\n",
    "        spec_diff_stats = get_all_stats(spec_diff)\n",
    "        assert spec_diff_stats.shape == (6,)\n",
    "        feature = np.concatenate((feature, spec_diff_stats), axis=0)\n",
    "    assert feature.shape == (84,)\n",
    "\n",
    "    mfcc_feature = extract_mfccs(note_audio)\n",
    "    feature = np.concatenate((feature, mfcc_feature), axis=0)\n",
    "    assert feature.shape == (164,)\n",
    "\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_data = [] # huge matrix with features and labels for note events (normal, bend/release, vibrato)\n",
    "trans_data = [] # huge matrix with features and labels for note events (normal, hm/po, slide)\n",
    "\n",
    "file = \"ACDC - Back In Black (ver 4 by GuitarManiac09)_Angus Young_6_13s.wav\"\n",
    "y, sr = librosa.load(os.path.join(AUDIO_DIR, file), sr=None)\n",
    "\n",
    "anno_file = \"samples/anno/ACDC - Back In Black (ver 4 by GuitarManiac09)_Angus Young_6.json\"\n",
    "\n",
    "with open(anno_file) as anno:\n",
    "    annotation = json.load(anno)\n",
    "for i in range(len(annotation)):\n",
    "    note_event = annotation[i]\n",
    "    onset = note_event[\"time\"][\"start\"]\n",
    "    offset = onset + note_event[\"time\"][\"dur\"]\n",
    "    onset_sp = librosa.time_to_samples(onset, sr=sr)\n",
    "    offset_sp = librosa.time_to_samples(offset, sr=sr)\n",
    "    note_audio = y[onset_sp : offset_sp]\n",
    "    feature = extract_features(note_audio)\n",
    "    if note_event[\"effects\"][\"bend\"]:\n",
    "        label = 1\n",
    "    elif note_event[\"effects\"][\"vibrato\"]:\n",
    "        label = 2\n",
    "    else:\n",
    "        label = 0\n",
    "    feature_w_label = np.append(feature, label)\n",
    "    notes_data.append(feature_w_label)\n",
    "\n",
    "    # if the note event is the last one in the file, ignore its transitions \n",
    "    # because the transition won't be captured in the audio\n",
    "    if i == len(annotation) - 1:\n",
    "        break\n",
    "    tran_onset_sp = offset_sp - librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_offset_sp = offset_sp + librosa.time_to_samples(0.05, sr=sr)\n",
    "    tran_audio = y[tran_onset_sp : tran_offset_sp]\n",
    "    tran_feature = extract_features(tran_audio)\n",
    "    if note_event[\"effects\"][\"hammer\"]:\n",
    "        tran_label = 1\n",
    "    elif note_event[\"effects\"][\"slide\"]:\n",
    "        tran_label = 2\n",
    "    else:\n",
    "        tran_label = 0\n",
    "    tran_feature_w_label = np.append(tran_feature, tran_label)\n",
    "    trans_data.append(tran_feature_w_label)\n",
    "\n",
    "notes_data = np.array(notes_data)\n",
    "trans_data = np.array(trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_data[:, -1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59d85d0919029fe908500b29ceb55c54859f0fca8114ead43d175dc230632326"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('GTP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
